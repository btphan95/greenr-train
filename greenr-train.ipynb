{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Create an Image Dataset and Train an Image Classifier using FastAI\n\n*by: Binh Phan. Inspired by [Lesson 2](https://course.fast.ai/videos/?lesson=2) of FastAI. Thanks to Francisco Ingham and Jeremy Howard* \n\nIn this tutorial, we'll create an image dataset from Google Images and train a state-of-the-art image classifier extremely easily using the FastAI library. The FastAI library is built on top of the PyTorch deep learning framework, and provides commands that make training an image classifier very intuitive.\n\nFor this tutorial, we'll build a dandelion vs. grass classifier. Let's get started!"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"from fastai.vision import *","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Create an Image Dataset from Google Images**\n\nNote: this Kaggle kernel already has the dataset created from these instructions, so if you don't want to create your own dataset, feel free to skip this section and move straight to [6]\n\n**How to save a list of Google Image URLs into a csv file**\n\nGo to Google Images and search for *grass*. Initially, there will be ~50 images, so scroll down and press the button 'Show more results' at the end of the page until ~100 images have loaded. \n\nNow you must run some Javascript code in your browser which will save the URLs of all the images you want for you dataset.\n\nPress CtrlShiftJ in Windows/Linux and CmdOptJ in Mac, and a small window the javascript 'Console' will appear. That is where you will paste the JavaScript commands.\n\nRun the following commands in the prompt:\n\n```\nurls = Array.from(document.querySelectorAll('.rg_di .rg_meta')).map(el=>JSON.parse(el.textContent).ou);\nwindow.open('data:text/csv;charset=utf-8,' + escape(urls.join('\\n')));\n```\n\nThe browser will download the file. Name the file *grass.csv*.\n\nRepeat the same steps above for *dandelion*, and save the respective file as *dandelion.csv*.\n\n**Upload the URLs as a dataset in Kaggle**\n\nIn this Kaggle kernel, go to File -> Add or upload data\n\nIn the top right corner, press Upload\n\nNow, add *grass.csv* and *dandelion.csv*. Name the dataset *greenr*."},{"metadata":{},"cell_type":"markdown","source":"Now, we're going to do a bit of hacky work to get things to work in Kaggle. The folder /kaggle/input is read-only, and we need to manipulate that folder to download the image URLs into our folder, so we're going to move the files to another folder, /kaggle/working. That's actually the output folder, but we'll let our dataset reside there and create the outputs in the same folder. Run the following command:"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"!cp -r /kaggle/input/greenr /kaggle/working","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, run the following commands to download the images from URLs into our dataset folder /kaggle/working/greenr/ using the *download_images* function.\n\nThen, we'll make sure all the images are valid using *verify_images*.\n\nAfter that, we'll create our dataset from *ImageDataBunch*. \n\nThese are all FastAI commands that make it really easy to create a dataset :)"},{"metadata":{"trusted":true},"cell_type":"code","source":"classes = ['grass','dandelion']\nfolder = 'grass'\nfile = 'grass.csv'\npath = Path('/kaggle/working/greenr/')\ndest = path/folder\ndest.mkdir(parents=True, exist_ok=True)\ndownload_images(path/file, dest, max_pics=200)\nfolder = 'dandelion'\nfile = 'dandelion.csv'\npath = Path('/kaggle/working/greenr/')\ndest = path/folder\ndest.mkdir(parents=True, exist_ok=True)\ndownload_images(path/file, dest, max_pics=200)\n\nfor c in classes:\n    print(c)\n    verify_images(path/c, delete=True, max_size=500)\n\nnp.random.seed(42)\ndata = ImageDataBunch.from_folder(path, train=\".\", valid_pct=0.2,\n        ds_tfms=get_transforms(), size=224, num_workers=4).normalize(imagenet_stats)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now let's view our data and see that we have a dataset. Congrats, you now have created your own image dataset!"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.classes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.show_batch(rows=3, figsize=(7,8))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.classes, data.c, len(data.train_ds), len(data.valid_ds)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train our Image Classifier\nNow, let's train an image classifer from our dataset. After this, we'll have a model that classifies dandelions vs. grass."},{"metadata":{},"cell_type":"markdown","source":"First, let's import a ResNet34 model using *cnn_learner*. ResNet34 is a pre-trained image classifier that works really well out of the box, and we're simply going to train that model on our dataset to get it to become an expert at classifying dandelions vs. grass!\n\nWe'll train on the dataset, find the best learning rate, and save our model using the following commands:"},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = cnn_learner(data, models.resnet34, metrics=error_rate)\nlearn.fit_one_cycle(4)\nlearn.save('stage-1')\nlearn.unfreeze()\nlearn.lr_find()\nlearn.recorder.plot()\nlearn.fit_one_cycle(2, max_lr=slice(3e-5,3e-4))\nlearn.save('stage-2')\nlearn.load('stage-2');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Interpretation\nLet's see how well our model did using a confusion matrix."},{"metadata":{"trusted":true},"cell_type":"code","source":"interp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Cleaning Up\n\nSome of our top losses aren't due to bad performance by our model. There are images in our data set that shouldn't be.\n\nUsing the `ImageCleaner` widget from `fastai.widgets` we can prune our top losses, removing photos that don't belong.\n\nSimply mark `delete` to any image that doesn't belong"},{"metadata":{"trusted":true},"cell_type":"code","source":"from fastai.widgets import *\ndb = (ImageList.from_folder(path)\n                   .split_none()\n                   .label_from_folder()\n                   .transform(get_transforms(), size=224)\n                   .databunch()\n     )\nlearn_cln = cnn_learner(db, models.resnet34, metrics=error_rate)\n\nlearn_cln.load('stage-2');\nds, idxs = DatasetFormatter().from_toplosses(learn_cln)\nImageCleaner(ds, idxs, path)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's also remove duplicates using this widget:"},{"metadata":{"trusted":true},"cell_type":"code","source":"ds, idxs = DatasetFormatter().from_similars(learn_cln)\nImageCleaner(ds, idxs, path, duplicates=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Awesome work! Now, let's retrain our model on our pruned dataset and make it even more accurate!"},{"metadata":{"trusted":false},"cell_type":"code","source":"np.random.seed(42)\ndata = ImageDataBunch.from_csv(path, folder=\".\", valid_pct=0.2, csv_labels='cleaned.csv',\n        ds_tfms=get_transforms(), size=224, num_workers=4).normalize(imagenet_stats)\nlearn = cnn_learner(data, models.resnet34, metrics=error_rate)\nlearn.fit_one_cycle(4)\nlearn.save('stage-1')\nlearn.unfreeze()\nlearn.lr_find()\nlearn.recorder.plot()\nlearn.fit_one_cycle(2, max_lr=slice(3e-5,3e-4))\nlearn.save('stage-2')\nlearn.load('stage-2');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's see if our confusion matrix has improved:"},{"metadata":{"trusted":false},"cell_type":"code","source":"interp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Great work! Now, let's export our model, which will create a file named `export.pkl` in our `/kaggle/working/greenr` directory. We can now use this model to make predictions on other images, and deploy it into production! Let's try it out:"},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.export()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"defaults.device = torch.device('cpu')\nimg = open_image(path/'grass'/'00000019.jpg')\nimg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = load_learner(path)\npred_class,pred_idx,outputs = learn.predict(img)\npred_class","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If you got *grass* above, then your model works! Congrats, you've now created your own image dataset and trained your own image classifier, using FastAI!\n\nIf you'd like to export your model into production, simply download the `export.pkl` file and move it to wherever you want to make your predictions, like your phone or a web application :)\n\nFor a live demo of a deployed web app of greenr and its source code, please visit my repository!\n\n[https://github.com/btphan95/greenr](https://github.com/btphan95/greenr)"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}